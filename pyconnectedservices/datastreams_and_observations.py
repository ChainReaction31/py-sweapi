import json
import uuid
from dataclasses import dataclass
from datetime import datetime, timezone
from uuid import UUID

import requests
from oshdatacore.component_implementations import DataRecordComponent
from oshdatacore.encoding import AbstractEncoding

from pyconnectedservices.constants import APITerms, ObservationFormat
from pyconnectedservices.system import System


@dataclass(kw_only=True)
class Datastream:
    """
    Datastreams define the structure of data sent to an OSH Node. They provide a means of defining what and how
    data must be packaged.

    Attributes:
        name: Human readable name for the datastream
        description: A brief description of the datastream
        output_name: The machine name of the datastream, often lowercase and hyphenated (e.g. 'your-output')
        encoding: One of the supported encodings
        root_component: The DataRecordComponent that is the root of the datastream
        obs_format: The observation format of the datastream (e.g. 'application/om+json')
        schema: The JSON schema of the datastream. Generated by create_datastream_schema()
        parent_system: The parent system of the datastream
        __ds_id: The internal id of the datastream
    """
    name: str
    description: str
    output_name: str
    encoding: AbstractEncoding
    obs_format: ObservationFormat
    parent_system: System
    root_component: DataRecordComponent = None
    schema: dict = None
    __field_map: dict = None
    __ds_id: str = None
    __observations: list = None

    def get_fields(self):
        return self.root_component.get_fields()

    def create_datastream_schema(self):
        """
        create the schema for the datastream, returns the schema if it already exists
        :return:
        """
        if self.schema is None:
            schema = dict([
                ('obsFormat', self.obs_format),
                ('resultSchema', self.root_component.datastructure_to_dict()),
                ('resultEncoding', vars(self.encoding))
            ])
            self.schema = schema
            return schema
        else:
            return self.schema

    # TODO: Test this method thoroughly
    def insert_datastream(self):
        """
        Insert the datastream into the parent system. Throws an error if the parent system is not set.
        """

        if self.parent_system is not None:
            datastream_dict = dict([
                ('outputName', self.output_name),
                ('name', self.name),
                ('description', self.description),
                ('schema', self.create_datastream_schema()),
            ])

            full_url = self.get_ds_insert_url()
            r = requests.post(full_url, json=datastream_dict, headers={'Content-Type': 'application/json'})
            print(f'\n{json.dumps(datastream_dict, indent=4)}\n')
            location = r.headers.get('Location')
            self.__ds_id = location.removeprefix('/datastreams/')
            return self.__ds_id
        else:
            raise ParentSystemNotFound()

    def get_datastream_url(self):
        return f'{self.parent_system.get_system_url()}/{APITerms.DATASTREAMS.value}/{self.__ds_id}'

    def get_ds_insert_url(self):
        return f'{self.parent_system.get_system_url()}/{self.parent_system.get_sys_id()}/{APITerms.DATASTREAMS.value}'

    def get_observation_url(self):
        return f'{self.get_datastream_url()}/{APITerms.OBSERVATIONS.value}'

    def add_root_component(self, component: DataRecordComponent):
        self.root_component = component
        self.set_field_map()

    def get_ds_id(self):
        return self.__ds_id

    def add_field(self, field):
        self.root_component.add_field(field)
        # TODO: it is not performant to rebuild the field map every time a field is added,
        #  change this in a future version
        self.set_field_map()

    def add_value_by_uuid(self, value, uuid):
        self.__field_map[uuid].value = value

    def get_field_map(self):
        self.set_field_map()
        return self.__field_map

    def set_field_map(self):
        self.__field_map = self.root_component.get_field_map()

    def create_observation_from_current(self):
        new_obs = Observation(parent_datastream=self)
        self.__observations

    def send_earliest_observation(self):
        """
        Sends the first observation in the list of observations. These should be in chronological order, though setting
        manual times for can break this. To prevent issues it is recommended that observations be sent as they are created
        or created in chronological order.
        :return:
        """
        url = self.get_observation_url()
        if self.__observations is not None and len(self.__observations) > 0:
            obs = self.__observations[0]
            # TODO: we'll need to handle this differently when dealing with a binary datastream
            r = requests.post(url, json=obs.to_dict(), headers={'Content-Type': 'application/json'})
            if r.status_code == 201:
                self.__observations.pop(0)
                return True
            else:
                return False

    def send_observation_batch(self, batch_size: int):
        """
        Attempts to send a batch of observations to the OSH Node. Actual number of observations will be the least of
        the batch size and the number of observations in the list.
        """
        url = self.get_observation_url()
        batch = self.__observations[:batch_size]
        # TODO: as in send_earliest_observation, we'll need to handle this differently when dealing with a
        #  binary datastream
        r = requests.post(url, json=batch, headers={'Content-Type': 'application/json'})
        if r.status_code == 201:
            # Remove the observations that were sent
            self.__observations = self.__observations[batch_size:]
            return True
        else:
            return False


@dataclass
class Observation:
    id: UUID = uuid.uuid4()
    parent_datastream: Datastream = None
    __name_value_map: dict = None
    __observation_dict: dict = None

    def create_name_value_map(self):
        self.parent_datastream.set_field_map()
        self.__name_value_map = dict([])
        for field in self.parent_datastream.get_field_map().values():
            self.__name_value_map[field.name] = field.value
        return self.__name_value_map

    def create_observation_dict(self):
        self.__observation_dict = dict([
            ('phenomenonTime', datetime.now(timezone.utc).isoformat()),
            ('result', self.create_name_value_map())
        ])
        return self.__observation_dict

    def create_observation_dict_with_time(self, obs_time: datetime):
        self.__observation_dict = dict([
            ('phenomenonTime', obs_time.isoformat()),
            ('result', self.create_name_value_map())
        ])
        return self.__observation_dict

    def get_observation_dict(self):
        return self.__observation_dict

    def get_observation_json(self):
        return json.dumps(self.__observation_dict, indent=4)


class ParentSystemNotFound(Exception):

    def __init__(self, message="Cannot insert datastream without a parent system"):
        self.message = message
        super().__init__(self.message)


class InvalidDatastream(Exception):
    def __init__(self, message=f'The Datastream cannot be built. Please check that all required fields are set'):
        self.message = message
        super().__init__(self.message)
